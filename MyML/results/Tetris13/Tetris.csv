Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.57592,29.78787878787879,-2.3557942,-10.153286546468735,-10.153286546468735,26.231628,0.25941277,0.00029967434,0.19989145,0.0004994681,1.0
2000,3.3962867,26.52777777777778,-4.625362,-8.48981668551763,-8.48981668551763,16.966131,0.24494907,0.0002990913,0.19969709,0.0004985158,1.0
3000,3.1590908,23.26829268292683,-4.9194565,-7.2814640242878985,-7.2814640242878985,8.554707,0.24050437,0.00029847963,0.19949321,0.00049751665,1.0
4000,2.9227276,22.295454545454547,-4.765468,-7.299022419886156,-7.299022419886156,6.497034,0.23013553,0.000297901,0.19930032,0.0004965716,1.0
