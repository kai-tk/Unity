Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.601145,30.25,3.543865,12.093547605699108,12.093547605699108,743.8915,0.23982278,0.0002996953,0.19989842,0.00049950235,1.0
2000,3.3361323,24.0,13.930168,26.470000076293946,26.470000076293946,398.07092,0.23335607,0.00029911107,0.1997037,0.00049854815,1.0
3000,3.0505767,18.51923076923077,23.35684,42.48269184736105,42.48269184736105,539.7781,0.23777622,0.00029851793,0.19950598,0.0004975793,1.0
4000,2.9731777,15.94915254237288,36.90474,52.5593204498291,52.5593204498291,346.91733,0.2369451,0.00029791647,0.19930549,0.00049659685,1.0
