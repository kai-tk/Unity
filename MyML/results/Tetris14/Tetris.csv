Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.6217413,28.5,-7.5255485,-915.3591253107244,-915.3591253107244,352285.12,0.25636777,0.00029968895,0.1998963,0.00049949187,1.0
2000,3.4586706,28.114285714285714,-25.263071,-897.9931884765625,-897.9931884765625,316272.62,0.25899887,0.00029910577,0.19970192,0.0004985394,1.0
3000,3.4583545,23.625,-51.56466,-802.2379142761231,-802.2379142761231,287683.6,0.24523695,0.00029850108,0.19950035,0.00049755175,1.0
