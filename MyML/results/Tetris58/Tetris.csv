Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.5637393,27.166666666666668,0.20168447,0.6081427991390228,0.6081427991390228,0.058525458,0.24529655,0.00029968284,0.19989428,0.000499482,1.0
2000,3.4663064,27.685714285714287,0.12759365,0.5868570966379983,0.5868570966379983,0.013464037,0.26413617,0.0002990997,0.1996999,0.0004985295,1.0
3000,3.0517316,24.615384615384617,0.18958224,0.5933332813855929,0.5933332813855929,0.019499507,0.2533039,0.00029848024,0.19949344,0.00049751776,1.0
