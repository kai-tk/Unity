Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.608811,31.419354838709676,30.034311,98.88290697733561,98.88290697733561,2387.2346,0.24425694,0.0002996797,0.19989324,0.0004994768,1.0
2000,3.5136554,30.65625,75.97117,104.32038116455078,104.32038116455078,281.00574,0.24438328,0.00029910114,0.1997004,0.00049853185,1.0
3000,3.4247606,28.61764705882353,83.41749,100.0556827993954,100.0556827993954,242.88498,0.244484,0.00029848947,0.19949648,0.0004975328,1.0
