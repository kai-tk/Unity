Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.6152463,30.96875,-5.65038,-215.1622585173576,-215.1622585173576,8070.2666,0.25936058,0.0002996859,0.1998953,0.000499487,1.0
2000,3.4680939,31.225806451612904,-52.86758,-222.34773451282132,-222.34773451282132,3086.5024,0.2546262,0.00029909753,0.19969916,0.00049852603,1.0
3000,3.253625,21.477272727272727,-81.259735,-159.81794808127663,-159.81794808127663,1019.4954,0.25270808,0.00029848574,0.19949526,0.0004975267,1.0
