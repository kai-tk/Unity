Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.65406,30.6875,-0.008595524,0.05283871545426307,0.05283871545426307,0.0011798231,0.25783747,0.00029968395,0.19989465,0.0004994838,1.0
2000,3.2544775,28.90909090909091,-0.03703115,0.047333339737220245,0.047333339737220245,0.00072003726,0.2687316,0.0002991017,0.19970058,0.0004985329,1.0
3000,3.171422,30.21875,-0.037616737,0.05018750764429569,0.05018750764429569,0.00077225355,0.24397373,0.0002985057,0.1995019,0.0004975593,1.0
