Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.6159527,31.483870967741936,-7.022282,-15.403332710266113,-15.403332710266113,700.08875,0.24276763,0.0002996906,0.19989689,0.0004994947,1.0
2000,3.5568821,30.65625,-17.384396,-16.322498977184296,-16.322498977184296,841.51483,0.23458073,0.0002991076,0.19970253,0.0004985424,1.0
3000,3.522712,31.161290322580644,-27.41569,-12.441933539605909,-12.441933539605909,660.067,0.26499367,0.00029850137,0.19950047,0.0004975522,1.0
4000,3.331895,31.06451612903226,-20.896475,-5.611934169646232,-5.611934169646232,1913.1259,0.22149491,0.00029791734,0.19930577,0.0004965983,1.0
5000,3.1106741,31.21875,-20.811974,-11.615936160087585,-11.615936160087585,146.94005,0.24451542,0.00029730363,0.1991012,0.0004955959,1.0
6000,3.080958,32.166666666666664,-21.288944,-6.269666481018066,-6.269666481018066,1179.7092,0.23734242,0.00029668384,0.1988946,0.00049458357,1.0
7000,2.989603,33.275862068965516,-22.242458,-6.9837897070522965,-6.9837897070522965,693.3915,0.24387464,0.0002960859,0.1986953,0.00049360696,1.0
8000,2.621486,32.333333333333336,-20.807512,-8.238998190561931,-8.238998190561931,348.0318,0.23813221,0.00029548476,0.1984949,0.0004926251,1.0
9000,2.0882692,33.275862068965516,-20.317066,3.916897412004142,3.916897412004142,1106.8048,0.24055615,0.00029487093,0.19829032,0.0004916225,1.0
10000,2.1630728,30.15625,-18.983185,-12.151873230934143,-12.151873230934143,108.880844,0.2558307,0.00029429642,0.19809881,0.0004906841,1.0
