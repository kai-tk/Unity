Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.6247876,30.09090909090909,-0.006369981,0.0004939305181324016,0.0004939305181324016,0.0010652833,0.24328616,0.00029968255,0.19989419,0.0004994815,1.0
2000,3.5433333,29.84375,0.0030925544,0.0004983152075510588,0.0004983152075510588,3.2523687e-05,0.24783894,0.0002991052,0.19970173,0.0004985385,1.0
3000,3.44759,31.741935483870968,-0.00050474226,0.0005363832211925558,0.0005363832211925558,3.34372e-05,0.24607338,0.00029851528,0.19950509,0.0004975749,1.0
4000,3.453199,29.59375,0.003811992,0.0004912118947686395,0.0004912118947686395,0.00065753335,0.24875304,0.00029792258,0.19930753,0.0004966069,1.0
