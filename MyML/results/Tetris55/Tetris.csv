Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.6255882,30.12121212121212,0.12959936,0.6489061992615461,0.6489061992615461,0.017093293,0.27887884,0.00029968238,0.19989412,0.0004994813,1.0
2000,3.5048096,33.206896551724135,0.15417482,0.7412068484158352,0.7412068484158352,0.011072367,0.24246332,0.00029910088,0.1997003,0.0004985315,1.0
3000,3.0409532,26.61111111111111,0.12249531,0.5998610729972521,0.5998610729972521,0.012245054,0.25364822,0.00029848242,0.19949414,0.00049752125,1.0
