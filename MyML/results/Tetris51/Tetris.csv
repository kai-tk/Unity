Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.5409377,26.833333333333332,-0.9215962,-1.3195077283041818,-1.3195077283041818,0.12740229,0.25503755,0.00029968793,0.19989598,0.0004994903,1.0
2000,3.219162,23.333333333333332,-1.0655881,-1.1881966789563496,-1.1881966789563496,0.12767537,0.24631558,0.0002991111,0.19970368,0.00049854803,1.0
3000,2.9435134,21.767441860465116,-1.0869842,-1.2919535054716953,-1.2919535054716953,0.0017836924,0.23354411,0.00029850248,0.19950081,0.0004975541,1.0
