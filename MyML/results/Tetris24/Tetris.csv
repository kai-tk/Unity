Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
1000,3.6615617,30.151515151515152,-2.2071376,-45.209998071193695,-45.209998071193695,476.7871,0.2502663,0.00029968575,0.19989526,0.00049948675,1.0
2000,3.5356946,27.457142857142856,-13.600634,-43.52799840654646,-43.52799840654646,230.97673,0.2471527,0.00029911482,0.19970493,0.00049855415,1.0
3000,3.1046522,20.304347826086957,-15.040912,-32.571302932241686,-32.571302932241686,188.12485,0.23799747,0.00029849794,0.19949931,0.00049754657,1.0
4000,3.1384172,16.982142857142858,-13.4439945,-27.611428090504237,-27.611428090504237,89.45257,0.23872225,0.00029789578,0.19929859,0.0004965632,1.0
